{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Detection in Videos\n",
    "\n",
    "We are going to cover the topics of background subtraction and erosion, and explain how these techniques can be used to isolate foreground objects and therefore detect motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to build a model of the background scene of the video based on some recent number of video frames and then compare that model to some current frame.\n",
    "\n",
    "We can create a foreground mask that quantifies the difference between the background model and the current frame and therefore the highlighted portions of the foreground mask can be interpreted as those regions of the video that contain motion.\n",
    "\n",
    "To remove the noisy pixels from the foreground mask we use an operation called *erosion*, when we apply erosion to this foreground mask we can achieve the eroded foreground mask which is totally black.\n",
    "\n",
    "---\n",
    "\n",
    "There's several functions in OpenCV that we'll be using to implement the erosion.\n",
    "\n",
    "+ createBackgroundSubtractorKNN(): Creates KNN background subtract and takes no required arguments, but it has three optional arguments\n",
    "\n",
    "1. history: Number of previous frames in the video stream, used to create a model for the background scene\n",
    "\n",
    "Some methods of the class are:\n",
    "\n",
    "1. apply(): Create a foregound mask, takes one required argument which is an image\n",
    "\n",
    "Once we have the foregound mask is to apply an erosion operation to it, so we are going to take the foreground mask and pass to the **erode** function along with the second required argument which is the kernel and that will produce for us an eroded foreground.\n",
    "\n",
    "\n",
    "Once we have an eroded foreground mask we want to identify all the non-zero pixels in that mask, so that we can identify the region where motion is occurring, for that purpose, we are going to use the **finNonZero** function and it takes one required argument which is the mask that we produced above and its going to return an array of of coordinates of all the non-zero pixels in the eroded foregrouns mask.\n",
    "\n",
    "Finally we can use the **boundingRect** function and we are going to pass that funtion the array of coordinates that we computed above. This will return a bounding box which encompasses all of the non-zero pixels in the eroded foreground mask, this return a tuple of the coordinates of the rectangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create video capture and video writer object\n",
    "input_video = \"../motion_test.mp4\"\n",
    "video_cap = cv2.VideoCapture(input_video)\n",
    "if not video_cap.isOpened():\n",
    "    print(f\"Unable to open: {input_video}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_w = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_h = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "size = (frame_w, frame_h)\n",
    "size_quad = (int(2 * frame_w), int(2 * frame_h))\n",
    "\n",
    "video_out_quad = cv2.VideoWriter(\"Video_out_quad.mp4\", cv2.VideoWriter_fourcc(*\"XVID\"), fps, size_quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution and Analysis\n",
    "# Convenience function for annotating video frames\n",
    "def drawBannerText(frame, text, banner_height_percent=0.08, font_scale=.8, text_color=(0, 255, 0), font_thickness=2):\n",
    "    # Draw a black filled banner across the top of the image frame.\n",
    "    # percent: set the banner height as a percentage of the frame height.\n",
    "    banner_height = int(banner_height_percent * frame.shape[0])\n",
    "    cv2.rectangle(frame, (0, 0), (frame.shape[1], banner_height), (0, 0, 0), thickness=-1)\n",
    "    \n",
    "    # Draw text on banner.\n",
    "    left_offset = 20\n",
    "    location = (left_offset, int(10 + (banner_height_percent * frame.shape[0]) / 2))\n",
    "    cv2.putText(frame, text, location, cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, font_thickness, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_sub = cv2.createBackgroundSubtractorKNN(history=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process video\n",
    "ksize = (5, 5)\n",
    "red = (0, 0, 255)\n",
    "yellow = (0, 255, 255)\n",
    "\n",
    "# Quad view that will be built.\n",
    "# ------------------------------\n",
    "# frame_fg_mask         :  frame\n",
    "# frame_fg_mask_erode   :  frame_eorde\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_cap.read()\n",
    "    \n",
    "    if frame is None:\n",
    "        break\n",
    "    else:\n",
    "        frame_erode = frame.copy()\n",
    "        \n",
    "        \n",
    "    # Tage 1: Motion area based on foreground mask.\n",
    "    fg_mask = bg_sub.apply(frame)\n",
    "    motion_area = cv2.findNonZero(fg_mask)  # Return an array of pixel coordinates for all non-zero pixels\n",
    "    x, y, w, h = cv2.boundingRect(motion_area)  # Give a bounding box that encompasses all of the non-zero pixels\n",
    "    \n",
    "    # Stage 2: Motion area based on foreground mask (with erosion)\n",
    "    fg_mask_erode = cv2.erode(fg_mask, np.ones(ksize, np.uint8))\n",
    "    motion_area_erode = cv2.findNonZero(fg_mask_erode)\n",
    "    xe, ye, we, he = cv2.boundingRect(motion_area_erode)\n",
    "    \n",
    "    # Draw bounding box for motion area based on foreground mask\n",
    "    if motion_area is not None:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), red, thickness=6)\n",
    "        \n",
    "    # Draw bounding box for motion area based on foreground mask (with erosion)\n",
    "    if motion_area_erode is not None:\n",
    "        cv2.rectangle(frame_erode, (xe, ye), (xe + we, ye + he), red, thickness=6)\n",
    "        \n",
    "    # Convert foreground masks to color so we can build a composite video with color annotations.\n",
    "    frame_fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "    frame_fg_mask_erode = cv2.cvtColor(fg_mask_erode, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Annotate each video frame.\n",
    "    drawBannerText(frame_fg_mask, \"Foreground Mask\")\n",
    "    drawBannerText(frame_fg_mask_erode, \"Foreground Mask Eroded\")\n",
    "    \n",
    "    # Build quad view.\n",
    "    frame_top = np.hstack([frame_fg_mask, frame])\n",
    "    frame_bot = np.hstack([frame_fg_mask_erode, frame_erode])\n",
    "    frame_composite = np.vstack([frame_top, frame_bot])\n",
    "    \n",
    "    # Create composite video with intermediate results (quad grid).\n",
    "    fc_h, fc_w, _ = frame_composite.shape\n",
    "    cv2.line(frame_composite, (0, int(fc_h / 2)), (fc_w, int(fc_h / 2)), yellow, thickness=1, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    # Write cideo files.\n",
    "    video_out_quad.write(frame_composite)\n",
    "    \n",
    "video_cap.release()\n",
    "video_out_quad.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
