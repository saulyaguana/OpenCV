{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: Intrusion Detection\n",
    "\n",
    "In this notebook, we are going to demonstrate how to build an intrusion detection application that monitors a surveillance video stream for unexpected behaivor. If an intrusion is detected that portion of the video stream will be saved to preserve a record of the activity and could also trigger an alert notification.\n",
    "\n",
    "Topics covered in this notebook include:\n",
    "+ Using a background subtraction model to isolate moving objects in the foreground (creating a foreground mask)\n",
    "+ Using a method called \"erosion\" to remove noise from the background mask\n",
    "+ Using contours to further identify the most prominet regions in the foreground subject\n",
    "\n",
    "We can filter on contour areas that are possibly more meaningful than sporadic or disconnected areas that can still occur in foreground mask that have been eroded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "+ Create a background subtractor object using **createBackgroundSubtratorKNN()**\n",
    "+ Apply the background subtractor to each video frame to create a foreground mask using the **apply()** method\n",
    "+ Apply erosion to the foreground mask to reduce noise using **erode()**\n",
    "+ Create contours from the eroded foreground mask using **findContours()**\n",
    "+ Find the largest contour from the previous step using the **sorted()** function\n",
    "+ Find the bounding rectangle of the largest contour using **boundingRect()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Video Capture and Video Writer Objects\n",
    "source = \"../intruder_1.mp4\"\n",
    "\n",
    "video_cap = cv2.VideoCapture(source)\n",
    "\n",
    "if not video_cap.isOpened():\n",
    "    print(f\"Unable to open: {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_w = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_h = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "size = (frame_w, frame_h)\n",
    "size_quad = (int(2 * frame_w), int(2 * frame_h))\n",
    "\n",
    "video_out_alert_file = \"video_out_alert_1.mp4\"\n",
    "video_out_quad_file = \"video_out_quad_1.mp4\"\n",
    "\n",
    "# Create video write objects.\n",
    "video_out_alert = cv2.VideoWriter(video_out_alert_file, cv2.VideoWriter_fourcc(*\"XVID\"), fps, size)\n",
    "video_out_quad = cv2.VideoWriter(video_out_quad_file, cv2.VideoWriter_fourcc(*\"XVID\"), fps, size_quad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBannerText(frame, text, banner_height_percent=0.08, font_scale=.8, text_color=(0, 255, 0), thickness=2):\n",
    "    # Draw a black filled banner across the top of the image frame.\n",
    "    # percent: set the banner height as a percentage of the frame height.\n",
    "    banner_height = int(banner_height_percent * frame.shape[0])\n",
    "    cv2.rectangle(frame, (0, 0), (frame.shape[1], banner_height), (0, 0, 0), thickness=-1)\n",
    "    \n",
    "    # Draw text on banner.\n",
    "    left_offset = 20\n",
    "    location = (left_offset, int(10 + (banner_height * frame.shape[0]) / 2))\n",
    "    cv2.putText(frame, text, location, cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, thickness, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create background subtraction object\n",
    "\n",
    "The background subtraction object created below will be used to process each frame in the video stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_sub = cv2.createBackgroundSubtractorKNN(history=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process video for analysis\n",
    "\n",
    "The code below contains extra logic required to produce an anlysis video that contans four views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksize = (5, 5)  # kernel size for erosion.\n",
    "max_contours = 3  # Number of contours to use for rendering a bounding rectangle.\n",
    "frame_count = 0 \n",
    "frame_start = 5  # Allow this number of frames to bootstrap the generation of a background model.\n",
    "red = (0, 0, 255)\n",
    "yellow = (0, 255, 255)\n",
    "green = (0, 255, 0)\n",
    "\n",
    "# Quad view that will be built.\n",
    "#-------------------------------------------\n",
    "# frame_fg_mask          :  frame\n",
    "# frame_fg_mask_erode_c  :  frame_erode_c\n",
    "#-------------------------------------------\n",
    "\n",
    "# Process video frames.\n",
    "while True:\n",
    "    ret, frame = video_cap.read()\n",
    "    frame_count += 1\n",
    "    if frame is None:\n",
    "        break\n",
    "    else:\n",
    "        frame_erode_c = frame.copy()\n",
    "        \n",
    "    # Stage 1: Create a foreground mask for the current frame.\n",
    "    fg_mask = bg_sub.apply(frame)\n",
    "    \n",
    "    # Wait a few frames for the background model to learn.\n",
    "    if frame_count > frame_start:\n",
    "        # Stage 1: Motion area based on foreground mask\n",
    "        motion_area = cv2.findNonZero(fg_mask)\n",
    "        if motion_area is not None:\n",
    "            x, y, w, h = cv2.boundingRect(motion_area)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), red, thickness=2)\n",
    "            drawBannerText(frame, \"Intrusion Alert\", text_color=red)\n",
    "            \n",
    "        # Stage 2: Stafe 1 + Erosion\n",
    "        fg_mask_erode_c = cv2.erode(fg_mask, np.ones(ksize, np.uint8))\n",
    "        motion_area_erode = cv2.findNonZero(fg_mask_erode_c)\n",
    "        if motion_area_erode is not None:\n",
    "            xe, ye, we, he = cv2.boundingRect(motion_area_erode)\n",
    "            cv2.rectangle(frame_erode_c, (xe, ye), (xe + we, ye + he), red, thickness=2)\n",
    "            drawBannerText(frame_erode_c, \"Intrusion Alert\", text_color=red)\n",
    "            \n",
    "        # Convert foreground masks to color so we can build a composite cideo with color annotations.\n",
    "        frame_fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "        frame_fg_mask_erode_c = cv2.cvtColor(fg_mask_erode_c, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # Stage 3: Stage 2 + Contours\n",
    "        contours_erode, hierarchy = cv2.findContours(fg_mask_erode_c, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if len(contours_erode) > 0:\n",
    "            # Annotate eroded foreground mask with contours.\n",
    "            cv2.drawContours(frame_fg_mask_erode_c, contours_erode, -1, green, thickness=2)\n",
    "            \n",
    "            # Sort contours based on area.\n",
    "            contours_sorted = sorted(contours_erode, key=cv2.contourArea, reverse=True)\n",
    "            \n",
    "            # Compute bounding rectangle for the top N largest contours.\n",
    "            for idx in range(min(max_contours, len(contours_sorted))):\n",
    "                xc, yc, wc, hc = cv2.boundingRect(contours_sorted[idx])\n",
    "                if idx == 0:\n",
    "                    x1 = xc\n",
    "                    y1 = yc\n",
    "                    x2 = xc + wc\n",
    "                    y2 = yc + hc\n",
    "                else:\n",
    "                    x1 = min(x1, xc)\n",
    "                    y1 = min(y1, yc)\n",
    "                    x2 = max(x2, xc + wc)\n",
    "                    y2 = max(y2, yc + hc)\n",
    "                    \n",
    "            # Draw bounding rectangle for top N contours on output frame.\n",
    "            cv2.rectangle(frame_erode_c, (x1, y1), (x2, y2), yellow, thickness=2)\n",
    "            drawBannerText(frame_erode_c, \"Intrusion Alert\", text_color=red)\n",
    "            \n",
    "        # Annotate each video frame.\n",
    "        drawBannerText(frame_fg_mask, \"Foreground Mask\")\n",
    "        drawBannerText(frame_fg_mask_erode_c, \"Foreground Mask (Eroded + Contours)\")\n",
    "        \n",
    "        # Build quad view.\n",
    "        frame_top = np.hstack([frame_fg_mask, frame])\n",
    "        frame_bot = np.hstack([frame_fg_mask_erode_c, frame_erode_c])\n",
    "        frame_composite = np.vstack([frame_top, frame_bot])\n",
    "        \n",
    "        # Annotate quad views with dividers.\n",
    "        fc_h, fc_w, _ = frame_composite.shape\n",
    "        cv2.line(frame_composite, (int(fc_w/2), 0), (int(fc_w/2), fc_h), yellow , thickness=3, lineType=cv2.LINE_AA)\n",
    "        cv2.line(frame_composite, (0, int(fc_h / 2)), (fc_w, int(fc_h / 2)), yellow, thickness=3, lineType=cv2.LINE_AA)\n",
    "        \n",
    "        # Wite video output files.\n",
    "        video_out_alert.write(frame_erode_c)  # Alert\n",
    "        video_out_quad.write(frame_composite)  # Analysis quad view\n",
    "        \n",
    "video_cap.release()\n",
    "video_out_alert.release()\n",
    "video_out_quad.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application Code\n",
    "\n",
    "The code below has been simplified to only include the portions required to produce the final alert video. However, an additional step has been added that checks the size of the largest contour in the eroded foreground mask relative to an input threshold fraction of the total frame area. The purpose of this threshold check is to help minimize false positives by requiring that the largest contour exceeds a certain fraction to the total frame area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"../intruder_2.mp4\"  # Or specify 'source' as the index associated with your camera system.\n",
    "\n",
    "video_cap2 = cv2.VideoCapture(source)\n",
    "if not video_cap2.isOpened():\n",
    "    print(f\"Unable to open: {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_w = int(video_cap2.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_h = int(video_cap2.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video_cap2.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "size = (frame_w, frame_h)\n",
    "frame_area = frame_w * frame_h\n",
    "\n",
    "video_out_alert_file_2 = \"viddeo_out_alert_2.mp4\"\n",
    "video_out_alert_2 = cv2.VideoWriter(video_out_alert_file_2, cv2.VideoWriter_fourcc(*\"XVID\"), fps, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_sub = cv2.createBackgroundSubtractorKNN(history=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksize = (5, 5)  # Kernel size for erosion.\n",
    "max_contours = 3  # Number of contours to use for rendering a bounding rectangle.\n",
    "frame_count = 0\n",
    "min_contour_area_thresh = .01  # Minumim fraction of frame required for maximum contour.\n",
    "\n",
    "yellow = (0, 255, 255)\n",
    "red = (0, 0, 255)\n",
    "\n",
    "# Process video frames.\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = video_cap2.read()\n",
    "    frame_count += 1\n",
    "    if frame is None:\n",
    "        break\n",
    "    \n",
    "    # Stage 1: Create a foreground mask for the current frame.\n",
    "    fg_mask = bg_sub.apply(frame)\n",
    "    \n",
    "    # Stage 2: Stage 1 + Erosion.\n",
    "    fg_mask_erode = cv2.erode(fg_mask, np.ones(ksize, np.uint8))\n",
    "    \n",
    "    # Stage 3: Stage 2 + Contours.\n",
    "    contours_erode, hierarchy = cv2.findContours(fg_mask_erode, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours_erode) > 0:\n",
    "        # Sort contours based on area.\n",
    "        contours_sorted = sorted(contours_erode, key=cv2.contourArea, reverse=True)\n",
    "        \n",
    "        # Contour areas of largest contour/\n",
    "        contour_area_max = cv2.contourArea(contours_sorted[0])\n",
    "        \n",
    "        # Computer fraction of total frame area occupied by largest contour.\n",
    "        contour_frac = contour_area_max / frame_area\n",
    "        \n",
    "        # Confirm contour_frac is freater than min_contour_area_thresh threshold.\n",
    "        if contour_frac > min_contour_area_thresh:\n",
    "            # Compute bounding rectangle for the top N largest contours.\n",
    "            for idx in range(min(max_contours, len(contours_sorted))):\n",
    "                xc, yc, wc, hc = cv2.boundingRect(contours_sorted[idx])\n",
    "                if idx == 0:\n",
    "                    x1 = xc\n",
    "                    y1 = yc\n",
    "                    x2 = xc + wc\n",
    "                    y2 = yc + hc\n",
    "                else:\n",
    "                    x1 = min(x1, xc)\n",
    "                    y1 = min(y1, yc)\n",
    "                    x2 = max(x2, xc + wc)\n",
    "                    y2 = max(y2, yc + hc)\n",
    "                    \n",
    "            # Draw bounding rectangle for top N contours on output frame.\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), yellow, thickness=2)\n",
    "            drawBannerText(frame, \"Intrusion Alert\", text_color=red)\n",
    "            \n",
    "            # Write alert video to file system.\n",
    "            video_out_alert_2.write(frame)\n",
    "            \n",
    "video_cap2.release()\n",
    "video_out_alert_2.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
